{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "%matplotlib inline\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data and convert it to pandas\n",
    "data=[]\n",
    "with open('class-data-with-all-tests-and-concept-check-NO_IDENTIFIERS.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "    \n",
    "headers = data[0]\n",
    "rest = data[1:]\n",
    "\n",
    "everything = pd.DataFrame(rest, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_int(dat):\n",
    "    return dat.apply(lambda x: int(x) if x else 0)\n",
    "def score1a(data):\n",
    "    return (data['1a'] == 'c').astype(int)\n",
    "def score1b(data):\n",
    "    a,b,c,d,e,f = as_int(data['1b.a']),as_int(data['1b.b']),as_int(data['1b.c']),as_int(data['1b.d']),as_int(data['1b.e']),as_int(data['1b.f'])\n",
    "    return (a+(1-b)+c+(1-d)+e+(1-f))/6\n",
    "def score2a(data):\n",
    "    return (data['2a'] == 'a').astype(int)\n",
    "def score2b(data):\n",
    "    return (data['2b'] == '0').astype(int)\n",
    "def score2c(data):\n",
    "    a,b,c,d,e = map(as_int, (data['2c.a'],data['2c.b'],data['2c.c'],data['2c.d'],data['2c.e']))\n",
    "    return ((1-a)+b+(1-c)+(1-d)+(1-e))/5\n",
    "def score3(data):\n",
    "    a,b,c,d,e,f = map(as_int, (data['3.a'],data['3.b'],data['3.c'],data['3.d'],data['3.e'],data['3.f']))\n",
    "    return ((1-a)+b+c+d+(1-e)+f)/6\n",
    "def score4a(data):\n",
    "    return (data['4a'] == 'd').astype(int)\n",
    "def score5(data):\n",
    "    a,b,c,d,e = map(as_int, (data['5.a'],data['5.b'],data['5.c'],data['5.d'],data['5.e']))\n",
    "    return (a+(1-b)+(1-c)+d+(1-e))/5\n",
    "def score6a(data):\n",
    "    return (data['6a'] == '1').astype(int)\n",
    "def score6b(data):\n",
    "    return (data['6b'] == 'c').astype(int)\n",
    "def score7(data):\n",
    "    return (data['7'] == 'd').astype(int)\n",
    "def score8(data):\n",
    "    a,b,c,d,e,f = map(as_int, (data['8.a'],data['8.b'],data['8.c'],data['8.d'],data['8.e'],data['8.f']))\n",
    "    return ((1-a)+(1-b)+(1-c)+(1-d)+e+(1-f))/6\n",
    "def score9a(data):\n",
    "    a,b,c,d,e,f,g,h,i = map(as_int, (data['9a.a'],data['9a.b'],data['9a.c'],data['9a.d'],data['9a.e'],data['9a.f'],data['9a.g'],data['9a.h'],data['9a.i']))\n",
    "    return (a+(1-b)+c+d+(1-e)+f+(1-g)+(1-h)+(1-i))/9\n",
    "def score9b(data):\n",
    "    a,b,c,d,e,f = map(as_int, (data['9b.a'],data['9b.b'],data['9b.c'],data['9b.d'],data['9b.e'],data['9b.f']))\n",
    "    return ((1-a)+(1-b)+(1-c)+(1-d)+e+(1-f))/6\n",
    "def score10(data):\n",
    "    a,b,c,d,e = map(as_int, (data['10.a'],data['10.b'],data['10.c'],data['10.d'],data['10.e']))\n",
    "    return ((1-a)+(1-b)+c+d+e)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1a</th>\n",
       "      <th>1b</th>\n",
       "      <th>2a</th>\n",
       "      <th>2b</th>\n",
       "      <th>2c</th>\n",
       "      <th>3</th>\n",
       "      <th>4a</th>\n",
       "      <th>5</th>\n",
       "      <th>6a</th>\n",
       "      <th>6b</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9a</th>\n",
       "      <th>9b</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1a    1b    2a    2b    2c     3    4a     5    6a    6b     7     8  \\\n",
       "mean  0.8  0.92  0.95  0.88  0.86  0.73  0.77  0.80  0.92  0.66  0.41  0.80   \n",
       "std   0.4  0.16  0.22  0.32  0.19  0.29  0.42  0.19  0.28  0.47  0.49  0.16   \n",
       "\n",
       "        9a    9b    10  \n",
       "mean  0.72  0.80  0.67  \n",
       "std   0.18  0.18  0.28  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessment = pd.DataFrame({\"1a\":score1a(everything),\"1b\":score1b(everything),\"2a\":score2a(everything),\n",
    "                           \"2b\":score2b(everything),\"2c\":score2c(everything),\"3\":score3(everything),\n",
    "                           \"4a\":score4a(everything),\"5\":score5(everything),\"6a\":score6a(everything),\n",
    "                           \"6b\":score6b(everything),\"7\":score7(everything),\"8\":score8(everything),\n",
    "                          \"9a\":score9a(everything),\"9b\":score9b(everything),\"10\":score10(everything)})\n",
    "\n",
    "assessment.describe().loc[['mean','std']].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by formatting our data before feeding it into a densely connected 3 layer network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe back to numpy array\n",
    "assessement_np = assessment.to_numpy()\n",
    "\n",
    "# Separate training data from testing data and grab labels\n",
    "train_data = assessement_np[:100]\n",
    "train_labels = everything['Final.total'].to_numpy()[:100].astype(np.float)\n",
    "\n",
    "test_data = assessement_np[100:]\n",
    "test_labels = everything['Final.total'].to_numpy()[100:].astype(np.float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 0s 587us/step - loss: 0.6871 - accuracy: 0.0100\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 671us/step - loss: 0.6913 - accuracy: 0.0100\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.6672 - accuracy: 0.0100\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 758us/step - loss: 0.6567 - accuracy: 0.0100\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 583us/step - loss: 0.6612 - accuracy: 0.0100\n",
      "6/6 [==============================] - 0s 564us/step - loss: 0.6582 - accuracy: 0.0061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6581882238388062, 0.006097560748457909]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Dense(15, activation='sigmoid', input_shape=(15,)),\n",
    "  Dense(15, activation='sigmoid'),\n",
    "  Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer=Adam(lr=0.05),\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_data,\n",
    "  train_labels,\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    ")\n",
    "\n",
    "# Evaluate the model.\n",
    "model.evaluate(\n",
    "    test_data,\n",
    "    test_labels\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "#model.save_weights('model.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('model.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "#predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "#print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "#print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
